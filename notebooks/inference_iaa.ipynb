{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q accelerate"
      ],
      "metadata": {
        "id": "etxWnxHHedZi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "import xgboost as xgb\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "K7tfN4eTdVIl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cls_model_spec(task, data_spec):\n",
        "    cls_model_spec = {\n",
        "        'knn': {\n",
        "            'cls': make_pipeline(\n",
        "                StandardScaler(),\n",
        "                KNeighborsClassifier(n_neighbors=len(data_spec[task]['label_names']))\n",
        "            )\n",
        "        },\n",
        "        'svc': {\n",
        "            'cls': make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "        },\n",
        "\n",
        "        'xgboost': {\n",
        "            'cls': xgb.XGBClassifier()\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return cls_model_spec"
      ],
      "metadata": {
        "id": "gw3TvGUcdTXG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_spec():\n",
        "    data_spec = {}\n",
        "\n",
        "    data_spec['Propaganda'] = {\n",
        "        'label2id': {\n",
        "          \"Not Propaganda\": 0,\n",
        "          \"Propaganda\": 1,\n",
        "          \"Unclear\": 2,\n",
        "          \"Not Applicable\": 3,\n",
        "        },\n",
        "        'id2label': {\n",
        "          \"0\": \"Not Propaganda\",\n",
        "          \"1\": \"Propaganda\",\n",
        "          \"2\": \"Unclear\",\n",
        "          \"3\": \"Not Applicable\",\n",
        "        },\n",
        "        'label_names': [\"Not Propaganda\", \"Propaganda\", \"Unclear\", \"Not Applicable\"],\n",
        "    }\n",
        "\n",
        "    data_spec['Bias'] = {\n",
        "\n",
        "        'label2id': {\n",
        "          \"Unbiased\": 0,\n",
        "          \"Biased against Palestine\": 1,\n",
        "          \"Biased against Israel\": 2,\n",
        "          \"Biased against both Palestine and Israel\": 3,\n",
        "          \"Biased against others\": 4,\n",
        "          \"Unclear\": 5,\n",
        "          \"Not Applicable\": 6\n",
        "        },\n",
        "        'id2label': {\n",
        "          \"0\": \"Unbiased\",\n",
        "          \"1\": \"Biased against Palestine\",\n",
        "          \"2\": \"Biased against Israel\",\n",
        "          \"3\": \"Biased against both Palestine and Israel\",\n",
        "          \"4\": \"Biased against others\",\n",
        "          \"5\": \"Unclear\",\n",
        "          \"6\": \"Not Applicable\"\n",
        "        },\n",
        "        'label_names': [\n",
        "            \"Unbiased\",\n",
        "            \"Biased against Palestine\",\n",
        "            \"Biased against Israel\",\n",
        "            \"Biased against both Palestine and Israel\",\n",
        "            \"Biased against others\",\n",
        "            \"Unclear\",\n",
        "            \"Not Applicable\"\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    return data_spec\n"
      ],
      "metadata": {
        "id": "NDnaqa6Jdc3j"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_model_spec():\n",
        "    embedding_model_spec = {\n",
        "        'ML-E5-large': {\n",
        "            'model_name': 'intfloat/multilingual-e5-large',\n",
        "            'max_length': 512,\n",
        "            'pooling_type': 'mean',\n",
        "            'normalize': True,\n",
        "            'batch_size': 1,\n",
        "            'kwargs': {'device_map': 'cuda', 'torch_dtype': torch.float16}\n",
        "        },\n",
        "        'BGE-M3': {\n",
        "            'model_name': 'BAAI/bge-m3',\n",
        "            'max_length': 8192,\n",
        "            'pooling_type': 'cls',\n",
        "            'normalize': True,\n",
        "            'batch_size': 1,\n",
        "            'kwargs': {'device_map': 'cuda', 'torch_dtype': torch.float16}\n",
        "        },\n",
        "        'E5-mistral-7b': {\n",
        "            'model_name': 'intfloat/e5-mistral-7b-instruct',\n",
        "            'max_length': 32768,\n",
        "            'pooling_type': 'last_token',\n",
        "            'normalize': True,\n",
        "            'batch_size': 1,\n",
        "            'kwargs': {'load_in_4bit': True, 'bnb_4bit_compute_dtype': torch.float16}\n",
        "        },\n",
        "        'Nomic-Embed': {\n",
        "            'model_name': 'nomic-ai/nomic-embed-text-v1',\n",
        "            'max_length': 8192,\n",
        "            'pooling_type': 'mean',\n",
        "            'normalize': True,\n",
        "            'batch_size': 1,\n",
        "            'kwargs': {'device_map': 'cuda', 'trust_remote_code': True}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    return embedding_model_spec"
      ],
      "metadata": {
        "id": "-a4YJINRddzb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pooling(model_output):\n",
        "    return torch.mean(model_output[\"last_hidden_state\"], dim=1)"
      ],
      "metadata": {
        "id": "rPJfFUIEfdkW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cls_pooling(model_output):\n",
        "    return model_output[0][:, 0]"
      ],
      "metadata": {
        "id": "RECFpGZDfe9y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def last_token_pooling(model_output):\n",
        "    return model_output[0][:, -1]"
      ],
      "metadata": {
        "id": "-EVaNIAnfhDf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentence_embedding(\n",
        "        text,\n",
        "        tokenizer,\n",
        "        embed_model,\n",
        "        normalize,\n",
        "        max_length,\n",
        "        pooling_type='cls'\n",
        "):\n",
        "    if pooling_type == \"last_token\":\n",
        "        encoded_input = tokenizer(\n",
        "            text,\n",
        "            max_length=max_length,\n",
        "            return_attention_mask=False,\n",
        "            padding=False,\n",
        "            truncation=True\n",
        "        )\n",
        "        encoded_input['input_ids'] = encoded_input['input_ids'] + [tokenizer.eos_token_id]\n",
        "        encoded_input = tokenizer.pad(\n",
        "            [encoded_input],\n",
        "            padding=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "    else:\n",
        "        encoded_input = tokenizer(\n",
        "            text,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=max_length,\n",
        "            truncation=True\n",
        "        ).to(\"cuda\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model_output = embed_model(**encoded_input)\n",
        "\n",
        "    sentence_embeddings = None\n",
        "    match pooling_type:\n",
        "        case \"cls\":\n",
        "            sentence_embeddings = cls_pooling(model_output)\n",
        "        case \"mean\":\n",
        "            sentence_embeddings = mean_pooling(model_output)\n",
        "        case \"last_token\":\n",
        "            sentence_embeddings = last_token_pooling(model_output)\n",
        "\n",
        "    if normalize:\n",
        "        sentence_embeddings = F.normalize(sentence_embeddings)\n",
        "\n",
        "    return sentence_embeddings"
      ],
      "metadata": {
        "id": "prceQMvLfbX5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def embed(embed_model, tokenizer, data, model_spec):\n",
        "    embeddings = [\n",
        "        get_sentence_embedding(\n",
        "            sentence,\n",
        "            tokenizer,\n",
        "            embed_model,\n",
        "            model_spec['normalize'],\n",
        "            model_spec['max_length'],\n",
        "            model_spec['pooling_type']\n",
        "        ) for sentence in data\n",
        "    ]\n",
        "\n",
        "    embeddings = torch.cat(embeddings)\n",
        "\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "-i5jgdXFfLlO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embeddings(embedding_method, embedding_model_spec, data, save_to):\n",
        "    print(\"Processing model : \" + str(embedding_model_spec))\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\n",
        "        embedding_model_spec[embedding_method]['model_name']\n",
        "    )\n",
        "\n",
        "    embed_model = AutoModel.from_pretrained(\n",
        "        embedding_model_spec[embedding_method]['model_name'],\n",
        "        **embedding_model_spec[embedding_method]['kwargs']\n",
        "    )\n",
        "\n",
        "    if embedding_method == \"Nomic-Embed\":\n",
        "        embed_model.to('cuda')\n",
        "\n",
        "    embeddings = embed(embed_model, tokenizer, data, embedding_model_spec[embedding_method])\n",
        "    embeddings = embeddings.detach().cpu()\n",
        "    print(f\"{embedding_method} embedding shape = {embeddings.shape}\")\n",
        "    torch.save(embeddings, save_to)"
      ],
      "metadata": {
        "id": "k5KikjbCdhXy"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test_splits(task, data_spec):\n",
        "    task_data_spec = data_spec[task]\n",
        "\n",
        "    data_dir = os.path.join(os.getcwd(), 'data')\n",
        "    task_data_dir = os.path.join(data_dir, task.lower())\n",
        "\n",
        "    train_data = pd.read_excel(os.path.join(task_data_dir, f'{task.lower()}_train_data.xlsx'))\n",
        "    test_data = pd.read_excel(os.path.join(task_data_dir, f'{task.lower()}_test_data.xlsx'))\n",
        "\n",
        "    label2id = task_data_spec['label2id']\n",
        "\n",
        "    train_data[task] = train_data[task].map(label2id)\n",
        "    test_data[task] = test_data[task].map(label2id)\n",
        "\n",
        "    data_splits = {\"train\": train_data, \"test\": test_data}\n",
        "\n",
        "    return data_splits"
      ],
      "metadata": {
        "id": "laPcrEEMdmq9"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XZKv0FTUYjuh"
      },
      "outputs": [],
      "source": [
        "def get_iaa_data(iaa_data_dir, iaa_index):\n",
        "    iaa_data = pd.read_excel(os.path.join(iaa_data_dir, f'iaa{iaa_index}.xlsx'))\n",
        "    return iaa_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_data(task, data_spec):\n",
        "    data_splits = get_train_test_splits(task, data_spec)\n",
        "    train_data = data_splits[\"train\"]\n",
        "\n",
        "    return train_data"
      ],
      "metadata": {
        "id": "V9glp8RhYwSM"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_embeddings(texts, embedding_model_spec, embedding_method, path):\n",
        "    create_embeddings(embedding_method, embedding_model_spec, texts, path)\n",
        "    embeddings = torch.load(path)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "0VKVXCXHYxLU"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(cls, train_data, x_pred, id2label):\n",
        "    x_train, y_train = train_data\n",
        "    cls.fit(x_train, y_train)\n",
        "    y_pred = cls.predict(x_pred)\n",
        "    predictions = [id2label[str(y_pred)] for y_pred in y_pred]\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "bL2myB9aY2vq"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    task = \"Propaganda\"\n",
        "    embedding_method = \"ML-E5-large\"\n",
        "    cls_method = \"knn\"\n",
        "    iaa_index = '1'\n",
        "\n",
        "    data_spec = get_data_spec()\n",
        "    data_dir = os.path.join(os.getcwd(), 'data')\n",
        "    train_data = get_train_data(task, data_spec)\n",
        "    train_texts = train_data[\"Text\"].tolist()\n",
        "\n",
        "    iaa_data_dir = os.path.join(data_dir, 'iaa')\n",
        "    iaa_data = get_iaa_data(iaa_data_dir, iaa_index)\n",
        "    iaa_texts = iaa_data[\"Text\"].tolist()\n",
        "\n",
        "    embedding_dir = os.path.join(os.getcwd(), 'embeddings')\n",
        "    Path(os.path.join(embedding_dir, 'iaa', task.lower())).mkdir(parents=True, exist_ok=True)\n",
        "    embedding_model_spec = get_embedding_model_spec()\n",
        "\n",
        "    train_embeddings = generate_embeddings(\n",
        "        train_texts,\n",
        "        embedding_model_spec,\n",
        "        embedding_method,\n",
        "        os.path.join(embedding_dir, task.lower(), f'{embedding_method}_train_embeddings.pt')\n",
        "    )\n",
        "\n",
        "    iaa_embeddings = generate_embeddings(\n",
        "        iaa_texts,\n",
        "        embedding_model_spec,\n",
        "        embedding_method,\n",
        "        os.path.join(embedding_dir, 'iaa', task.lower(), f'{embedding_method}_{iaa_index}_embeddings.pt')\n",
        "    )\n",
        "\n",
        "    cls_model_spec = create_cls_model_spec(task, data_spec)\n",
        "    cls = cls_model_spec[cls_method][\"cls\"]\n",
        "\n",
        "    x_train = train_embeddings\n",
        "    y_train = train_data[task].tolist()\n",
        "    x_pred = iaa_embeddings\n",
        "\n",
        "    task_predictions = predict(cls, (x_train, y_train), x_pred, data_spec[task]['id2label'])\n",
        "    iaa_data[task] = task_predictions\n",
        "    iaa_data.to_excel(\n",
        "        os.path.join(\n",
        "            data_dir,\n",
        "            'iaa',\n",
        "            f\"{task.lower()}_{embedding_method}_{cls_method}_iaa{iaa_index}_data.xlsx\"),\n",
        "        index=False\n",
        "    )"
      ],
      "metadata": {
        "id": "HpE7XBW4Y3O4"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "vyGtFMkHY7mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IcmS0DX5d7Za"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}