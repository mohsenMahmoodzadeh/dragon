{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42799efa-0b54-4976-94d2-e79dcbb80520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores import FAISS\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df7f845-b99f-456c-8392-f35616101122",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Bias\" # Bias or Propaganda\n",
    "model_path = 'intfloat/multilingual-e5-base'\n",
    "model_kwargs = {'device':'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe61c5-1624-4285-bfa2-65d4c984ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(os.getcwd())\n",
    "subset_data = pd.read_excel(os.path.join(path.parent.absolute(), 'data', task.lower(), f'{task.lower()}_train_data.xlsx'))\n",
    "query_data = pd.read_excel(os.path.join(path.parent.absolute(), 'data', task.lower(), f'{task.lower()}_test_data.xlsx'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975df4a8-addd-46b9-bf0a-be4ba6227db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_path, \n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5441e3-b5d2-45a3-8f35-21f889a8910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(page_content=d['Text'], metadata={\"label\": d[task],\"english_MT\": d[\"English MT\"], \"id\": id}) for id, d in subset_data.iterrows()\n",
    "]\n",
    "\n",
    "db = FAISS.from_documents(documents, embeddings)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": K})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557ee45-e35f-4ac9-99ba-b8b7e0d4814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_with_different_labels(query_text, retriever):\n",
    "  \"\"\"\n",
    "  Finds k most similar documents with different labels (among retrieved)\n",
    "  \"\"\"\n",
    "  similar_docs = retriever.get_relevant_documents(query_text)[1:]\n",
    "  similar_texts=[(relevant_doc.metadata['english_MT']) for relevant_doc in similar_docs]\n",
    "  similar_labels = [relevant_doc.metadata['label'] for relevant_doc in similar_docs]\n",
    "\n",
    "  # Get unique labels from retrieved documents\n",
    "  unique_labels = set(similar_labels)\n",
    "  k = len(unique_labels)\n",
    "  seen_labels=set()\n",
    "  result=[]\n",
    "  for i, (text, label) in enumerate(zip(similar_texts, similar_labels)):\n",
    "    if label in unique_labels and label not in seen_labels:\n",
    "      result.append((text, label))\n",
    "      seen_labels.add(label)\n",
    "      if len(result) == k:  # Stop once we have k unique pairs\n",
    "        break\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc3670-9f52-4328-b135-ca3f9fed06ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs_with_labels = []\n",
    "\n",
    "query_list = query_data[\"Text\"].tolist()\n",
    "query_list_english = query_data[\"English MT\"].tolist()\n",
    "\n",
    "for query in query_list:\n",
    "    output = find_similar_with_different_labels(query, retriever)\n",
    "    relevant_docs_with_labels.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd0f83-960f-4932-86d4-64b3b9a4dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatgpt_response(client, text):\n",
    "    responce = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0125\",\n",
    "        messages=[{\"role\": \"user\", \"content\": text}],\n",
    "    )\n",
    "\n",
    "    return responce.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7992f2b-2efa-4c91-ac05-ac3b0b4a96bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "client = OpenAI(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e006e3e-2990-4228-89af-5630b42edb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions_list=[\n",
    "    ('unbiased','This label is applied when the text presents information neutrally without favoring any particular side.'),\n",
    "    ('biased against palestine','This label is used when referring to the perception that media outlets demonstrate a tendency to favor one side or present Palestinians in a negative light, often through selective reporting or framing'),\n",
    "    ('biased against israel','Bias against Israel in media refers to the perception that media outlets demonstrate a tendency to favor one side or present Israel in a negative light, often through selective reporting or framing'),\n",
    "    ('unclear','This label is applied when the text does not clearly indicate its stance or exhibits ambiguity in its presentation, leaving the reader uncertain about the intended message.'),\n",
    "    ('not applicable','This label is applied when the text does not relate to the bias annotations or the conflict between Israel and Palestine.'),\n",
    "    ('biased against others','Bias against others in media refers to the perception that media outlets demonstrate a tendency to favor certain groups or individuals while presenting others in a negative light'),\n",
    "    ('biased against both palestine and israel','Bias against both Palestine and Israel in media refers to the perception that media outlets display a propensity to favor one side or portray both sides in a negative light')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56e897-953f-4466-ad42-0880d378325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the responses\n",
    "responses = []\n",
    "prompts=[]\n",
    "\n",
    "# Iterate over the list and generate the prompt for each string\n",
    "for query, examples in zip(query_list_english, relevant_docs_with_labels):\n",
    "\n",
    "    # Create a list to store the example prompts\n",
    "    example_prompts = []\n",
    "\n",
    "    # Iterate over the examples for the current query\n",
    "    for example in examples:\n",
    "        example_text = example[0]  # Get the text of the example\n",
    "        example_class = example[1]  # Get the class of the example\n",
    "\n",
    "        # Find the definition for the current example class\n",
    "        definition = next((definition for definition in definitions_list if example_class.upper() in definition[0].upper()), None)\n",
    "\n",
    "        # Create the prompt for each example with the definition\n",
    "        example_prompt = f\"{example_class}: {definition[1]}\\nExample: {example_text}\\n\"\n",
    "\n",
    "        example_prompts.append(example_prompt)\n",
    "\n",
    "    # Combine all the example prompts into a single string\n",
    "    examples_texts = \"\\n\".join(example_prompts)\n",
    "\n",
    "    # Create the complete prompt for the current query\n",
    "    prompt = f'''\n",
    "    Your task is to classify the following text, delimited with triple backticks, into one of the following categories with just the class name: {', '.join(set(example[1].upper() for example in examples))}.\n",
    "    The text is a news article that has been published during the Israel-Palestine conflict. Your task is to classify the news to identify potential biases in media narratives.\n",
    "\n",
    "    Here you can see th definition and examples of the classes:\n",
    "\n",
    "    {examples_texts}\n",
    "\n",
    "    Here is the news text to classify:\n",
    "    ```{query}```\n",
    "\n",
    "    just give back the class name from these classes: {', '.join(set(example[1].upper() for example in examples))}\n",
    "\n",
    "    '''\n",
    "    prompts.append(prompt)\n",
    "    response = get_chatgpt_response(client, prompt)\n",
    "    # Append the answer to the responses list\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa999d0-1082-4a4a-90fb-9f8063ce48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = [item.lower() for item in responses]\n",
    "responses = [string.replace('.', '') for string in responses]\n",
    "\n",
    "labels = query_data[task].tolist()\n",
    "labels = [item.lower() for item in labels]\n",
    "\n",
    "count = 0\n",
    "for i in range(len(responses)):\n",
    "    if responses[i] == labels[i]:\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b1a27f-b209-4ec4-9ddc-836fd36bfb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count / len(responses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc23b7f-b8bb-46b9-b31f-22cf4befe921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(labels, responses))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
